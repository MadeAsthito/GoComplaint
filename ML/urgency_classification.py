# -*- coding: utf-8 -*-
"""NLP_TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qTyTpG7_saUSceStpUqC_BVNk7cdF9sG
"""

#Import library
import pandas as pd
import numpy as np
import tensorflow as tf
import random
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from google.colab import files


#Load dataset
data = pd.read_csv('/content/Dataset Pengaduan Masyarakat.csv')
data = data[['complaint', 'urgency']]

#Preprocessing: Convert label
y = [ 0 if i=='Not Urgent' else 1 for i in data['urgency'] ]
x = data['complaint']

#Split dataset
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)

vocab_size = 500
embedding_dim = 64
max_length = 50
trunc_type='post'
padding_type='post'
oov_tok = "<OOV>"

#Tokenization
tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(x_train)
wordindex = tokenizer.word_index

train_seq = tokenizer.texts_to_sequences(x_train)
test_seq = tokenizer.texts_to_sequences(x_test)

train_padded = pad_sequences(train_seq, padding=padding_type, truncating=trunc_type, maxlen=max_length)
test_padded = pad_sequences(test_seq, padding=padding_type, truncating=trunc_type, maxlen=max_length)

train_padded = np.array(train_padded)
train_label = np.array(y_train)
test_padded = np.array(test_padded)
test_label = np.array(y_test)

#Sequential model
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(64, activation="relu"),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation="sigmoid")
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(train_padded, train_label, epochs=10, validation_data = (test_padded, test_label))

#Testing with real data
sentence = ["jalanan rusak parah sejak tahun lalu sering terjadi keclekaan, tolong diperbaiki pak"]
sequence = tokenizer.texts_to_sequences(sentence)
padded = pad_sequences(sequence, maxlen=max_length, padding=padding_type, truncating=trunc_type)

predict = model.predict(padded)
predict_value = predict[0][0]

#Urgency Percentage
print(f"Percentage: {predict_value * 100:.1f}%")

#Urgency Value
if predict_value > 0.5:
    print("Urgency = Urgent")
else:
    print("Urgency = Not Urgent")

#Save model h5
model.save('new_model77.h5')

#Download file h5
files.download('new_model77.h5')